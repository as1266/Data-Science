---
title: "INFO 3010 - Assignment 5"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Spring 2020 by Lingzi Hong+
## Due: Monday, Mar 2, 2020
### Instructions
1. This is an R Markdown format used for publishing markdown documents to GitHub. When you click the **Knit** button, all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated.
2. Please download the snowstorm.json from canvas. Fill in the code chunks for following question and submit this R markdown file to the assignment on Canvas. Make sure when you save that you have run all cells, so the outputs displace between the cells.
3. make sure to replace the directoryID in the filename with your student ID. 


### Q1. (5pts) Load and parse the "snowstorm_sample2.json" file to a dataframe.
```{r}
library(streamR)
library(tm)
library(wordcloud)



setwd('/Users/anime/Documents/Data science' )

tweet_d<-parseTweets(tweets='snowstorm_sample2.json')

```

### Q2. (5pts) Take the text of tweet, compute the corpus and check the first 10 lines of the corpus.
```{r}
textd<- tweet_d$text
head(textd,10)
```

### Q3. (5pts) Use any stop words list and remove the stop words from corpus, then check the first 10 lines of the corpus.
```{r}
myStopword<-stopwords('english')
myCorpu <- tm_map(myCorpu, removeWords, myStopwords)
inspect(myCorpu[1:10])
```

### Q4. (5pts) Remove punctuations in the corpus, then check the first 10 lines of the corpus.
```{r}
myCorpu <- tm_map(myCorpu, removePunctuation)
inspect(myCorpu[1:10])
```

### Q5. (5pts) Convert all characters to lower case, then check the first 10 lines of the corpus. 
```{r}
myCorpu <- tm_map(myCorpu, tolower)
inspect(myCorpu[1:10])
```

### Q6. (5pts) Generate the document term matrix and check a slice of the matrix. 
```{r}
myDtm <- TermDocumentMatrix(myCorpu, control = list(minWordLength = 1))
inspect(myDtm[266:270, 31:40])
```

### Q7. (10pts) Get the total number of frequency for each word.
```{r}
m<- as.matrix(myDtm)
v<- sort(rowSums(m),decreasing = TRUE)
v
```

### Q8. (10pts) Get the ten most frequent words based on Q7. 
```{r}
myNames<- names(v)
d <-data.frame(word=myNames, freq=v) 
wordcloud(d$word,d$freq, min.freq =28 )

```

